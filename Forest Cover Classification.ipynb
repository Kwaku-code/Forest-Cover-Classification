{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "\n",
    "# from model import fit_model\n",
    "# from visualize import plot_accuracy, plot_heatmap\n",
    "# from report import class_names, report\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"cover_data.csv\")\n",
    "feature = df.iloc[:, : -1]\n",
    "labels = df.iloc[:, -1]\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    feature, \n",
    "    labels, \n",
    "    test_size = 0.2,\n",
    "    random_state = 42,\n",
    "    stratify = labels\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_train_scaled = scaler.fit_transform(features_train)\n",
    "features_test_scaled = scaler.transform(features_test)\n",
    "\n",
    "def design_model(learning_rate):\n",
    "\n",
    "    model = Sequential()\n",
    "    # Set the input layer:\n",
    "    model.add(InputLayer(input_shape = (features_train_scaled.shape[1],)))\n",
    "    \n",
    "    # Set the hidden layers:\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(16, activation = \"relu\"))\n",
    "    model.add(Dense(8, activation = \"relu\"))\n",
    "    # Set the output layer:\n",
    "    model.add(Dense(8, activation = \"softmax\"))\n",
    "    opt = Adam(learning_rate = learning_rate)\n",
    "    model.compile(\n",
    "        loss = \"sparse_categorical_crossentropy\",  \n",
    "        metrics = [\"accuracy\"], \n",
    "        optimizer = opt\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_model(learning_rate, num_epochs, batch_size):\n",
    "    model = design_model(learning_rate)\n",
    "    stop = EarlyStopping(\n",
    "        monitor = \"val_accuracy\", \n",
    "        mode = \"auto\",\n",
    "        verbose = 1, \n",
    "        patience = 10 \n",
    "    )\n",
    "    history = model.fit(\n",
    "        features_train,\n",
    "        labels_train,\n",
    "        epochs = num_epochs,\n",
    "        batch_size = batch_size,\n",
    "        verbose = 1,\n",
    "        validation_split = 0.1,        #  10% of the data would be allocated for validation\n",
    "        callbacks = [stop]\n",
    "    )\n",
    "    return history, features_test, labels_test\n",
    "\n",
    "\n",
    "\n",
    "def plot_accuracy(history):\n",
    "    # Plot accuracy\n",
    "    fig = plt.figure(figsize = (15,10))\n",
    "    ax1 = fig.add_subplot(2, 1, 1)\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('model accuracy')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.legend(['train', 'validation'], loc='upper left')\n",
    "    \n",
    "    # Plot loss and val_loss over each epoch\n",
    "    ax2 = fig.add_subplot(2, 1, 2)\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('plot learning curves')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.legend(['train', 'validation'], loc='upper left') \n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_heatmap(class_names, y_pred, y_test):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    heatmap = sns.heatmap(cm, fmt='g', cmap='Blues', annot=True, ax=ax)\n",
    "    ax.set_xlabel('Predicted class')\n",
    "    ax.set_ylabel('True class')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(class_names)\n",
    "    ax.yaxis.set_ticklabels(class_names)\n",
    "    # Save the heatmap to file\n",
    "    heatmapfig = heatmap.get_figure()\n",
    "    #heatmapfig.savefig(f'../output/confusion_matrix.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "class_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
    "                   'Ponderosa Pine', 'Cottonwood/Willow',\n",
    "                   'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "\n",
    "def report(model, features_test, labels_test):\n",
    "    score = model.evaluate(features_test, labels_test, verbose = 0)\n",
    "    print(f'Test loss: {score[0]}')\n",
    "    print(f'Test accuracy: {score[1]}')\n",
    "\n",
    "    # evaluating the model:\n",
    "    y_pred = model.predict(features_test)\n",
    "    # Convert the pred to discrete values\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    print(classification_report(labels_test, y_pred, target_names = class_names))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "learning_rate = 0.00005\n",
    "# Too many epochs can lead to overfitting, and too few to underfitting. \n",
    "num_epochs = 200\n",
    "batch_size = 1024\n",
    "\n",
    "history, features_test, labels_test = fit_model(learning_rate, num_epochs, batch_size)\n",
    "#pprint.pprint(history.__dict__)\n",
    "#pprint.pprint(history.model.__dict__)\n",
    "\n",
    "plot_accuracy(history)\n",
    "\n",
    "y_pred = report(history.model, features_test, labels_test)\n",
    "\n",
    "plot_heatmap(class_names, y_pred, labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
